const express = require('express');
const { BigQuery } = require('@google-cloud/bigquery');
const cors = require('cors');
const path = require('path');
const dotenv = require('dotenv');
const moment = require('moment');Â 

dotenv.config();

const projectId = process.env.GOOGLE_PROJECT_ID;
const bigQueryDataset = process.env.BIGQUERY_DATASET;
const bigQueryTable = process.env.BIGQUERY_TABLE; // Your main task table
const bigQueryTable2 = "Per_Key_Per_Day";
const bigQueryTable3 = "Per_Person_Per_Day";

// ðŸš€ NEW: Status Update Backup Table ðŸš€
const bigQueryStatusUpdateTable = "StatusUpdatesBackup"; 
// Note: This table name will be used with the target dataset 'PMS' as defined in the BQ DML INSERT query.

const app = express();

// Middleware setup
const allowedOrigins = [
Â  Â  'http://localhost:3000',Â 
Â  Â  /^https:\/\/.*\.vercel\.app$/,Â 
Â  Â  'https://scheduler-ui-roan.vercel.app'Â 
];

// --- 1. CORS CONFIGURATION ---
app.use(cors({
Â  Â  origin: function (origin, callback) {
Â  Â  Â  Â  if (!origin) return callback(null, true);

Â  Â  Â  Â  const isAllowed = allowedOrigins.some(allowedOrigin => {
Â  Â  Â  Â  Â  Â  if (typeof allowedOrigin === 'string') {
Â  Â  Â  Â  Â  Â  Â  Â  return allowedOrigin === origin;
Â  Â  Â  Â  Â  Â  } else if (allowedOrigin instanceof RegExp) {
Â  Â  Â  Â  Â  Â  Â  Â  return allowedOrigin.test(origin);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  return false;
Â  Â  Â  Â  });

Â  Â  Â  Â  if (!isAllowed) {
Â  Â  Â  Â  Â  Â  const msg = 'The CORS policy for this site does not allow access from the specified Origin.';
Â  Â  Â  Â  Â  Â  return callback(new Error(msg), false);
Â  Â  Â  Â  }
Â  Â  Â  Â  return callback(null, true);
Â  Â  },
Â  Â  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],Â 
Â  Â  allowedHeaders: ['Content-Type', 'Authorization'],Â 
Â  Â  credentials: trueÂ 
}));
app.use(express.json());Â 

console.log('DEBUG: GOOGLE_PROJECT_ID:', process.env.GOOGLE_PROJECT_ID);
console.log('DEBUG: BIGQUERY_CLIENT_EMAIL:', process.env.BIGQUERY_CLIENT_EMAIL);
console.log('DEBUG: BIGQUERY_PRIVATE_KEY exists:', !!process.env.BIGQUERY_PRIVATE_KEY);

const bigQueryClient = new BigQuery({
Â  Â  projectId: projectId,
Â  Â  credentials: {
Â  Â  Â  Â  client_email: process.env.BIGQUERY_CLIENT_EMAIL,
Â  Â  Â  Â  private_key: process.env.BIGQUERY_PRIVATE_KEY ? process.env.BIGQUERY_PRIVATE_KEY.replace(/\\n/g, '\n') : undefined,
Â  Â  },
});

// Define admin emails on the backend for consistency and security
const ADMIN_EMAILS_BACKEND = [
Â  Â  "systems@brightbraintech.com",
Â  Â  "neelam.p@brightbraintech.com",
Â  Â  "meghna.j@brightbraintech.com",
Â  Â  "divya.s@brightbraintech.com",
Â  Â  "zoya.a@brightbraintech.com",
Â  Â  "altaf.s@brightbraintech.com",
Â  Â  "arvanbir.s@brightbraintech.com"
];

const SYSTEM_EMAIL_FOR_GLOBAL_TASKS = "systems@brightbraintech.com";


// Endpoint to fetch people mapping
app.get('/api/people-mapping', async (req, res) => {
Â  Â  const NATIVE_PEOPLE_TABLE = 'People_To_Email_Mapping_Native'; // <--- CHANGE THIS TO YOUR NEW NATIVE TABLE NAME IF DIFFERENT
Â  Â  const query = `
Â  Â  Â  Â  SELECT Current_Employes, Emp_Emails
Â  Â  Â  Â  FROM \`${projectId}.${bigQueryDataset}.${NATIVE_PEOPLE_TABLE}\`
Â  Â  `;

Â  Â  try {
Â  Â  Â  Â  const [rows] = await bigQueryClient.query(query);
Â  Â  Â  Â  const formattedRows = rows.map(row => ({
Â  Â  Â  Â  Â  Â  Current_Employes: row.Current_Employes,
Â  Â  Â  Â  Â  Â  Emp_Emails: row.Emp_Emails
Â  Â  Â  Â  }));
Â  Â  Â  Â  res.status(200).json(formattedRows);
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('Error fetching people mapping from BigQuery:', error);
Â  Â  Â  Â  res.status(500).send({ error: 'Failed to fetch people mapping data.' });
Â  Â  }
});

// ðŸš€ UPDATED ENDPOINT: Fetch only Active Unique Clients for the Filter Dropdown ðŸš€
app.get('/api/active-clients', async (req, res) => {
Â  Â  // This query assumes your main table (bigQueryTable) has the 'Client' and 'Inactive' columns.
Â  Â  // We are filtering for rows where 'Inactive' is explicitly 'Active'.
Â  Â  const query = `
Â  Â  Â  Â  SELECT DISTINCT Client
Â  Â  Â  Â  FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
Â  Â  Â  Â  WHERE Inactive = 'Active'Â 
Â  Â  Â  Â  AND Client IS NOT NULLÂ 
Â  Â  Â  Â  ORDER BY Client
Â  Â  `;

Â  Â  try {
Â  Â  Â  Â  const [rows] = await bigQueryClient.query(query);
Â  Â  Â  Â  // Map the result to an array of client names
Â  Â  Â  Â  const activeClients = rows.map(row => row.Client);
Â  Â  Â  Â  console.log(`Backend: Fetched ${activeClients.length} active unique clients.`);
Â  Â  Â  Â  res.status(200).json(activeClients);
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('Error fetching active clients from BigQuery:', error);
Â  Â  Â  Â  res.status(500).send({ error: 'Failed to fetch active client list.' });
Â  Â  }
});


// GET workflow headers only, with filtering for non-admins
app.get('/api/data', async (req, res) => {
Â  Â  const userEmail = req.query.email;Â 
Â  Â  const searchQuery = req.query.searchQuery;Â 
Â  Â  const clientFilter = req.query.clientFilter;Â 

Â  Â  let query;
Â  Â  let params = {};
Â  Â  let whereClauses = [`Step_ID = 0`];Â 

Â  Â  if (userEmail && !ADMIN_EMAILS_BACKEND.includes(userEmail)) {
Â  Â  Â  Â  whereClauses.push(`DelCode_w_o__ IN (
Â  Â  Â  Â  Â  Â  SELECT DISTINCT DelCode_w_o__
Â  Â  Â  Â  Â  Â  FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
Â  Â  Â  Â  Â  Â  WHERE Emails LIKE @userEmail OR Emails LIKE @systemEmail
Â  Â  Â  Â  )`);
Â  Â  Â  Â  params.userEmail = `%${userEmail}%`;
Â  Â  Â  Â  params.systemEmail = `%${SYSTEM_EMAIL_FOR_GLOBAL_TASKS}%`;
Â  Â  Â  Â  console.log(`Filtering workflow headers for non-admin user: ${userEmail}`);
Â  Â  } else if (userEmail && ADMIN_EMAILS_BACKEND.includes(userEmail)) {
Â  Â  Â  Â  console.log(`Fetching all workflow headers for admin user: ${userEmail}`);
Â  Â  } else {
Â  Â  Â  Â  console.log(`Fetching all workflow headers (no user email provided or default behavior)`);
Â  Â  }

Â  Â  if (searchQuery) {
Â  Â  Â  Â  whereClauses.push(`(Task_Details LIKE @searchQuery OR Delivery_code LIKE @searchQuery)`);
Â  Â  Â  Â  params.searchQuery = `%${searchQuery}%`;
Â  Â  Â  Â  console.log(`Applying search filter: ${searchQuery}`);
Â  Â  }

Â  Â  if (clientFilter) {
Â  Â  Â  Â  whereClauses.push(`Client = @clientFilter`);
Â  Â  Â  Â  params.clientFilter = clientFilter;
Â  Â  Â  Â  console.log(`Applying client filter: ${clientFilter}`);
Â  Â  }

Â  Â  query = `SELECT * FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
Â  Â  Â  Â  Â  Â  Â WHERE ${whereClauses.join(' AND ')}`;

Â  Â  try {
Â  Â  Â  Â  const [rows] = await bigQueryClient.query({
Â  Â  Â  Â  Â  Â  query: query,
Â  Â  Â  Â  Â  Â  params: params,
Â  Â  Â  Â  Â  Â  location: 'US',Â 
Â  Â  Â  Â  });
Â  Â  Â  Â  res.status(200).json(rows);
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('Error fetching data from BigQuery for /api/data:', error);
Â  Â  Â  Â  res.status(500).send({ error: 'Failed to fetch data from BigQuery.' });
Â  Â  }
});

// FIXED ENDPOINT: /api/workflow-details/:deliveryCode (GET all tasks for a specific workflow)
app.get('/api/workflow-details/:deliveryCode', async (req, res) => {
Â  Â  const { deliveryCode } = req.params;
Â  Â  const query = `
Â  Â  Â  Â  SELECTÂ 
Â  Â  Â  Â  Â  Â  Key,Â 
Â  Â  Â  Â  Â  Â  Delivery_code,
Â  Â  Â  Â  Â  Â  DelCode_w_o__,
Â  Â  Â  Â  Â  Â  Step_ID,
Â  Â  Â  Â  Â  Â  Task_Details,
Â  Â  Â  Â  Â  Â  Frequency___Timeline,
Â  Â  Â  Â  Â  Â  Client,
Â  Â  Â  Â  Â  Â  Short_Description,
Â  Â  Â  Â  Â  Â  Planned_Start_Timestamp,
Â  Â  Â  Â  Â  Â  Planned_Delivery_Timestamp,
Â  Â  Â  Â  Â  Â  Responsibility,
Â  Â  Â  Â  Â  Â  Current_Status,
Â  Â  Â  Â  Â  Â  Emails,
Â  Â  Â  Â  Â  Â  Total_Tasks,
Â  Â  Â  Â  Â  Â  Completed_Tasks,
Â  Â  Â  Â  Â  Â  Planned_Tasks,
Â  Â  Â  Â  Â  Â  Percent_Tasks_Completed,
Â  Â  Â  Â  Â  Â  Created_at,
Â  Â  Â  Â  Â  Â  Updated_at,
Â  Â  Â  Â  Â  Â  Time_Left_For_Next_Task_dd_hh_mm_ss,
Â  Â  Â  Â  Â  Â  Card_Corner_Status
Â  Â  Â  Â  FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
Â  Â  Â  Â  WHERE DelCode_w_o__ = @deliveryCode
Â  Â  `;
Â  Â  const params = { deliveryCode: deliveryCode };

Â  Â  try {
Â  Â  Â  Â  const [rows] = await bigQueryClient.query({
Â  Â  Â  Â  Â  Â  query: query,
Â  Â  Â  Â  Â  Â  params: params,
Â  Â  Â  Â  Â  Â  location: 'US',
Â  Â  Â  Â  });
Â  Â  Â  Â  res.status(200).json(rows);
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error(`Error fetching workflow details for ${deliveryCode} from BigQuery:`, error);
Â  Â  Â  Â  res.status(500).send({ error: `Failed to fetch workflow details for ${deliveryCode}.` });
Â  Â  }
});


// NEW ENDPOINT: /api/per-key-per-day-by-key
app.get('/api/per-key-per-day-by-key', async (req, res) => {
Â  Â  const { key } = req.query;Â 
Â  Â  if (!key) {
Â  Â  Â  Â  return res.status(400).send({ error: 'Key parameter is required.' });
Â  Â  }

Â  Â  const query = `
Â  Â  Â  Â  SELECT Key, Day, Duration, Duration_Unit, Planned_Delivery_Slot, Responsibility
Â  Â  Â  Â  FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable2}\`
Â  Â  Â  Â  WHERE Key = @key
Â  Â  `;
Â  Â  const params = { key: parseInt(key, 10) };Â 
Â  Â  const queryTypes = {
Â  Â  Â  Â  key: 'INT64'Â 
Â  Â  };

Â  Â  try {
Â  Â  Â  Â  const [rows] = await bigQueryClient.query({
Â  Â  Â  Â  Â  Â  query: query,
Â  Â  Â  Â  Â  Â  params: params,
Â  Â  Â  Â  Â  Â  types: queryTypes,Â 
Â  Â  Â  Â  Â  Â  location: 'US',Â 
Â  Â  Â  Â  });

Â  Â  Â  Â  const groupedData = {
Â  Â  Â  Â  Â  Â  totalDuration: 0,
Â  Â  Â  Â  Â  Â  entries: []
Â  Â  Â  Â  };
Â  Â  Â  Â  rows.forEach(row => {
Â  Â  Â  Â  Â  Â  groupedData.entries.push(row);
Â  Â  Â  Â  Â  Â  groupedData.totalDuration += row.Duration || 0;Â 
Â  Â  Â  Â  });

Â  Â  Â  Â  if (rows.length === 0) {
Â  Â  Â  Â  Â  Â  return res.status(404).send({ message: 'No entries found for this key.' });
Â  Â  Â  Â  }

Â  Â  Â  Â  res.status(200).json(groupedData);
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error(`Error fetching Per_Key_Per_Day data for Key ${key} from BigQuery:`, error);
Â  Â  Â  Â  res.status(500).send({ error: `Failed to fetch Per_Key_Per_Day data for Key ${key}.` });
Â  Â  }
});


// Existing /api/per-key-per-day route (kept for other potential uses)
app.get('/api/per-key-per-day', async (req, res) => {
Â  Â  const query = `SELECT * FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable2}\``;
Â  Â  try {
Â  Â  Â  Â  const [rows] = await bigQueryClient.query(query);
Â  Â  Â  Â  const groupedData = {};
Â  Â  Â  Â  rows.forEach(row => {
Â  Â  Â  Â  Â  Â  const key = row.Key;
Â  Â  Â  Â  Â  Â  if (!groupedData[key]) {
Â  Â  Â  Â  Â  Â  Â  Â  groupedData[key] = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  totalDuration: 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entries: []
Â  Â  Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  groupedData[key].entries.push(row);
Â  Â  Â  Â  Â  Â  groupedData[key].totalDuration += row.Duration_In_Minutes || 0;
Â  Â  Â  Â  });
Â  Â  Â  Â  res.status(200).json(groupedData);
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('Error fetching per-key-per-day data from BigQuery:', error);
Â  Â  Â  Â  res.status(500).send({ error: 'Failed to fetch per-key-per-day data from BigQuery.' });
Â  Â  }
});

// Existing /api/per-person-per-day route
app.get('/api/per-person-per-day', async (req, res) => {
Â  Â  const query = `SELECT * FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable3}\``;
Â  Â  try {
Â  Â  Â  Â  const [rows] = await bigQueryClient.query(query);
Â  Â  Â  Â  res.status(200).json(rows);
Â  Â  }
Â  Â  catch (error) {
Â  Â  Â  Â  console.error('Error fetching per-person-per-day data from BigQuery:', error);
Â  Â  Â  Â  res.status(500).send({ error: 'Failed to fetch per-person-per-day data from BigQuery.' });
Â  Â  }
});

// ðŸš€ NEW ENDPOINT: Update Task Status and Log to Backup Table ðŸš€
app.post('/api/task/status-update', async (req, res) => {
    console.log('Backend: Received POST request to /api/task/status-update');

    const { key, email, status } = req.body;

    if (!key || !email || !status) {
        return res.status(400).json({
            message: 'Bad Request: Key, email, and status are required in the request body.',
            details: 'Missing task key, user email, or status (Complete/Not Required).'
        });
    }

    if (status !== 'Complete' && status !== 'Not Required') {
        return res.status(400).json({
            message: 'Bad Request: Invalid status value.',
            details: 'Status must be "Complete" or "Not Required".'
        });
    }

    const targetDataset = 'PMS';
    const targetTable = bigQueryStatusUpdateTable; // "StatusUpdatesBackup"

    // 1. Update the main task table (bigQueryTable) to set the task's Current_Status
    // Also update Updated_at to reflect the change
    const updateMainTaskQuery = `
        UPDATE \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
        SET Current_Status = @status, Updated_at = CURRENT_DATETIME('Asia/Kolkata')
        WHERE Key = @key
    `;
    const updateMainTaskOptions = {
        query: updateMainTaskQuery,
        params: { key: parseInt(key, 10), status: status },
        types: { key: 'INT64', status: 'STRING' },
        location: 'US',
    };
    
    // 2. Log the Status Update (Insert into the Backup table)
    // Using BQ DML INSERT query to ensure the Timestamp is server-generated (CURRENT_TIMESTAMP()).
    const insertBackupQuery = `
        INSERT INTO \`stellar-acre-407408.${targetDataset}.${targetTable}\` (Timestamp, Email, Key, Status)
        VALUES (CURRENT_TIMESTAMP(), @email, @key, @status)
    `;
    const insertBackupOptions = {
        query: insertBackupQuery,
        params: { email: email, key: parseInt(key, 10), status: status },
        types: { email: 'STRING', key: 'INT64', status: 'STRING' },
        location: 'US',
    };

    try {
        // Run Main Task Update first
        console.log(`Backend: Updating main task status for Key ${key} to ${status}...`);
        const [updateMainTaskJob] = await bigQueryClient.createQueryJob(updateMainTaskOptions);
        await updateMainTaskJob.getQueryResults();

        // Run Backup Table Insert (Timestamp logging)
        console.log(`Backend: Logging status update to backup table for Key ${key}...`);
        const [insertBackupJob] = await bigQueryClient.createQueryJob(insertBackupOptions);
        await insertBackupJob.getQueryResults();
        
        console.log(`Backend: Key ${key} status successfully updated and logged.`);
        res.status(200).send({ message: 'Task status updated and logged successfully.' });

    } catch (error) {
        console.error('Backend: Error processing task status update:', error);
        res.status(500).json({
            message: 'Failed to update task status due to a backend error.',
            details: error.message || 'Unknown server error.',
        });
    }
});


// Modified POST route to handle both main task and Per_Key_Per_Day updates
app.post('/api/post', async (req, res) => {
Â  Â  console.log('Backend: Received POST request to /api/post');
Â  Â Â 

Â  Â  const { mainTask, perKeyPerDayRows } = req.body;

Â  Â  Â  Â  // Check if mainTask or its Key is missing
Â  Â  if (!mainTask || mainTask.Key === undefined || mainTask.Key === null || String(mainTask.Key) === '') {
Â  Â  Â  Â  console.error("Backend: mainTask or mainTask.Key is missing or empty in the request body.");
Â  Â  Â  Â  return res.status(400).json({
Â  Â  Â  Â  Â  Â  message: 'Bad Request: Task data or Task Key is missing in the request body.',
Â  Â  Â  Â  Â  Â  details: 'The server expected a "mainTask" object with a non-empty "Key" property but it was not found or was incomplete.'
Â  Â  Â  Â  });
Â  Â  }

Â  Â  const taskKeyString = String(mainTask.Key);
Â  Â  const userEmail = mainTask.Email; // Expecting user email from frontend payload

Â  Â  // --- 2. SERVER-SIDE RESPONSIBILITY CHANGE VALIDATION (SECURITY CHECK) ---
Â  Â  try {
Â  Â  Â  Â  const fetchCurrentTaskQuery = `
Â  Â  Â  Â  Â  Â  SELECT Responsibility
Â  Â  Â  Â  Â  Â  FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
Â  Â  Â  Â  Â  Â  WHERE Key = @key
Â  Â  Â  Â  `;
Â  Â  Â  Â  const fetchOptions = {
Â  Â  Â  Â  Â  Â  query: fetchCurrentTaskQuery,
Â  Â  Â  Â  Â  Â  params: { key: parseInt(taskKeyString, 10) },
Â  Â  Â  Â  Â  Â  types: { key: 'INT64' },
Â  Â  Â  Â  Â  Â  location: 'US',
Â  Â  Â  Â  };

Â  Â  Â  Â  const [currentRows] = await bigQueryClient.query(fetchOptions);
Â  Â  Â  Â  const currentTask = currentRows[0];
Â  Â  Â  Â Â 
Â  Â  Â  Â  // Check if the task exists and the Responsibility field is actually changing
Â  Â  Â  Â  if (currentTask && currentTask.Responsibility !== mainTask.Responsibility) {
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  const isAdmin = ADMIN_EMAILS_BACKEND.includes(userEmail);
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  // If the user is NOT an admin, reject the change
Â  Â  Â  Â  Â  Â  if (!isAdmin) {
Â  Â  Â  Â  Â  Â  Â  Â  console.warn(`SECURITY ALERT: Non-admin user ${userEmail} attempted to change Responsibility for Key ${taskKeyString} from "${currentTask.Responsibility}" to "${mainTask.Responsibility}".`);
Â  Â  Â  Â  Â  Â  Â  Â  return res.status(403).json({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  message: 'Forbidden: You do not have permission to change the Responsibility for an existing task.',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  details: 'Only Admin users can reassign tasks.'
Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  } catch (fetchError) {
Â  Â  Â  Â  console.error("Backend: Error during security check (fetching current task state):", fetchError);
Â  Â  Â  Â  // Do NOT block the request on this error to avoid an accidental DoS if BigQuery is slow,Â 
Â  Â  Â  Â  // but rely on the main update being accurate. A more rigorous implementation might halt here.
Â  Â  }
Â  Â  // --- END SERVER-SIDE VALIDATION ---


Â  Â  // Convert timestamps to BigQuery compatible format for mainTask
Â  Â  const formatTimestamp = (timestamp, type) => {
Â  Â  Â  Â  if (!timestamp) return null;
Â  Â  Â  Â  const cleanedTimestamp = typeof timestamp === 'string' ? timestamp.replace(' UTC', '') : timestamp;
Â  Â  Â  Â  const momentObj = moment.utc(cleanedTimestamp);
Â  Â  Â  Â  if (type === 'TIMESTAMP') {
Â  Â  Â  Â  Â  Â  return momentObj.isValid() ? momentObj.format('YYYY-MM-DD HH:mm:ss.SSSSSS') + ' UTC' : null;
Â  Â  Â  Â  } else if (type === 'DATETIME') {
Â  Â  Â  Â  Â  Â  return momentObj.isValid() ? momentObj.format('YYYY-MM-DD HH:mm:ss.SSSSSS') : null;
Â  Â  Â  Â  }
Â  Â  Â  Â  return null;
Â  Â  };

Â  Â  const formattedPlannedStartTimestamp = formatTimestamp(mainTask.Planned_Start_Timestamp, 'TIMESTAMP');
Â  Â  const formattedPlannedDeliveryTimestamp = formatTimestamp(mainTask.Planned_Delivery_Timestamp, 'TIMESTAMP');
Â  Â  const formattedCreatedAt = formatTimestamp(mainTask.Created_at, 'TIMESTAMP');
Â  Â  const formattedUpdatedAt = formatTimestamp(mainTask.Updated_at, 'DATETIME');


Â  Â  // Prepare data for the main task table update
Â  Â  const mainTaskRow = {
Â  Â  Â  Â  Key: mainTask.Key,
Â  Â  Â  Â  Delivery_code: mainTask.Delivery_code,
Â  Â  Â  Â  DelCode_w_o__: mainTask.DelCode_w_o__,
Â  Â  Â  Â  Step_ID: mainTask.Step_ID,
Â  Â  Â  Â  Task_Details: mainTask.Task_Details,
Â  Â  Â  Â  Frequency___Timeline: mainTask.Frequency___Timeline,
Â  Â  Â  Â  Client: mainTask.Client,
Â  Â  Â  Â  Short_Description: mainTask.Short_Description,
Â  Â  Â  Â  Planned_Start_Timestamp: formattedPlannedStartTimestamp,
Â  Â  Â  Â  Planned_Delivery_Timestamp: formattedPlannedDeliveryTimestamp,
Â  Â  Â  Â  Responsibility: mainTask.Responsibility,
Â  Â  Â  Â  Current_Status: mainTask.Current_Status,
Â  Â  Â  Â  Emails: mainTask.Emails,Â 
Â  Â  Â  Â  Total_Tasks: mainTask.Total_Tasks,
Â  Â  Â  Â  Completed_Tasks: mainTask.Completed_Tasks,
Â  Â  Â  Â  Planned_Tasks: mainTask.Planned_Tasks,
Â  Â  Â  Â  Percent_Tasks_Completed: mainTask.Percent_Tasks_Completed,
Â  Â  Â  Â  Created_at: formattedCreatedAt,
Â  Â  Â  Â  Updated_at: formattedUpdatedAt,
Â  Â  Â  Â  Time_Left_For_Next_Task_dd_hh_mm_ss: mainTask.Time_Left_For_Next_Task_dd_hh_mm_ss,
Â  Â  Â  Â  Card_Corner_Status: mainTask.Card_Corner_Status,
Â  Â  };

Â  Â  // Define types for nullable parameters in mainTaskRow for BigQuery UPDATE
Â  Â  const mainTaskParameterTypes = {
Â  Â  Â  Â  Key: 'INTEGER', // Assuming Key is an INTEGER in BigQuery
Â  Â  Â  Â  Delivery_code: 'STRING',
Â  Â  Â  Â  DelCode_w_o__: 'STRING',
Â  Â  Â  Â  Step_ID: 'INTEGER',
Â  Â  Â  Â  Task_Details: 'STRING',
Â  Â  Â  Â  Frequency___Timeline: 'STRING',
Â  Â  Â  Â  Client: 'STRING',
Â  Â  Â  Â  Short_Description: 'STRING',
Â  Â  Â  Â  Planned_Start_Timestamp: 'TIMESTAMP',
Â  Â  Â  Â  Planned_Delivery_Timestamp: 'TIMESTAMP',
Â  Â  Â  Â  Responsibility: 'STRING',
Â  Â  Â  Â  Current_Status: 'STRING',
Â  Â  Â  Â  Emails: 'STRING',
Â  Â  Â  Â  Total_Tasks: 'INTEGER',
Â  Â  Â  Â  Completed_Tasks: 'INTEGER',
Â  Â  Â  Â  Planned_Tasks: 'INTEGER',
Â  Â  Â  Â  Percent_Tasks_Completed: 'FLOAT',
Â  Â  Â  Â  Created_at: 'TIMESTAMP',
Â  Â  Â  Â  Updated_at: 'DATETIME',
Â  Â  Â  Â  Time_Left_For_Next_Task_dd_hh_mm_ss: 'STRING',
Â  Â  Â  Â  Card_Corner_Status: 'STRING',
Â  Â  };

Â  Â  try {
Â  Â  Â  Â  // 1. Update the main task table (componentv2)
Â  Â  Â  Â  const updateMainTaskQuery = `
Â  Â  Â  Â  Â  Â  UPDATE \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
Â  Â  Â  Â  Â  Â  SET
Â  Â  Â  Â  Â  Â  Â  Â  Delivery_code = @Delivery_code,
Â  Â  Â  Â  Â  Â  Â  Â  DelCode_w_o__ = @DelCode_w_o__,
Â  Â  Â  Â  Â  Â  Â  Â  Step_ID = @Step_ID,
Â  Â  Â  Â  Â  Â  Â  Â  Task_Details = @Task_Details,
Â  Â  Â  Â  Â  Â  Â  Â  Frequency___Timeline = @Frequency___Timeline,
Â  Â  Â  Â  Â  Â  Â  Â  Client = @Client,
Â  Â  Â  Â  Â  Â  Â  Â  Short_Description = @Short_Description,
Â  Â  Â  Â  Â  Â  Â  Â  Planned_Start_Timestamp = @Planned_Start_Timestamp,
Â  Â  Â  Â  Â  Â  Â  Â  Planned_Delivery_Timestamp = @Planned_Delivery_Timestamp,
Â  Â  Â  Â  Â  Â  Â  Â  Responsibility = @Responsibility,
Â  Â  Â  Â  Â  Â  Â  Â  Current_Status = @Current_Status,
Â  Â  Â  Â  Â  Â  Â  Â  Emails = @Emails,
Â  Â  Â  Â  Â  Â  Â  Â  Total_Tasks = @Total_Tasks,
Â  Â  Â  Â  Â  Â  Â  Â  Completed_Tasks = @Completed_Tasks,
Â  Â  Â  Â  Â  Â  Â  Â  Planned_Tasks = @Planned_Tasks,
Â  Â  Â  Â  Â  Â  Â  Â  Percent_Tasks_Completed = @Percent_Tasks_Completed,
Â  Â  Â  Â  Â  Â  Â  Â  Created_at = @Created_at,
Â  Â  Â  Â  Â  Â  Â  Â  Updated_at = @Updated_at,
Â  Â  Â  Â  Â  Â  Â  Â  Time_Left_For_Next_Task_dd_hh_mm_ss = @Time_Left_For_Next_Task_dd_hh_mm_ss,
Â  Â  Â  Â  Â  Â  Â  Â  Card_Corner_Status = @Card_Corner_Status
Â  Â  Â  Â  Â  Â  WHERE Key = @Key
Â  Â  Â  Â  `;
Â  Â  Â  Â  const updateMainTaskOptions = {
Â  Â  Â  Â  Â  Â  query: updateMainTaskQuery,
Â  Â  Â  Â  Â  Â  params: mainTaskRow,
Â  Â  Â  Â  Â  Â  types: mainTaskParameterTypes,Â 
Â  Â  Â  Â  Â  Â  location: 'US',
Â  Â  Â  Â  };
Â  Â  Â  Â  console.log('Backend: Executing main task update query...');
Â  Â  Â  Â  const [mainTaskJob] = await bigQueryClient.createQueryJob(updateMainTaskOptions);
Â  Â  Â  Â  await mainTaskJob.getQueryResults();
Â  Â  Â  Â  console.log(`Backend: Main task with Key ${mainTask.Key} updated successfully.`);


Â  Â  Â  Â  // 2. Safely Update/Replace Per_Key_Per_Day using MERGE
Â  Â  Â  Â  if (perKeyPerDayRows && perKeyPerDayRows.length > 0) {
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  // The source data for MERGE must be structured. Since you only have one row,Â 
Â  Â  Â  Â  Â  Â  // we will create a one-row temporary table using UNNEST.

Â  Â  Â  Â  Â  Â  const newRow = perKeyPerDayRows[0];
Â  Â  Â  Â  Â  Â  const targetKey = parseInt(mainTask.Key, 10);
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  // A more straightforward and less error-prone way is two sequential MERGE/DML statements:
Â  Â  Â  Â  Â  Â  // 2a. DELETE all existing rows for this key. (This is the failure point, but MERGE can fix it)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  const deleteMergeQuery = `
Â  Â  Â  Â  Â  Â  Â  Â  MERGE INTO \`${projectId}.${bigQueryDataset}.${bigQueryTable2}\` AS T
Â  Â  Â  Â  Â  Â  Â  Â  USING (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  SELECT @targetKey AS Key
Â  Â  Â  Â  Â  Â  Â  Â  ) AS S
Â  Â  Â  Â  Â  Â  Â  Â  ON T.Key = S.Key
Â  Â  Â  Â  Â  Â  Â  Â  WHEN MATCHED THEN DELETE
Â  Â  Â  Â  Â  Â  `;
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  const deleteMergeOptions = {
Â  Â  Â  Â  Â  Â  Â  Â  query: deleteMergeQuery,
Â  Â  Â  Â  Â  Â  Â  Â  params: { targetKey: targetKey },
Â  Â  Â  Â  Â  Â  Â  Â  types: { targetKey: 'INT64' },
Â  Â  Â  Â  Â  Â  Â  Â  location: 'US',
Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  console.log('Backend: Deleting existing perKeyPerDayRows using MERGE...');
Â  Â  Â  Â  Â  Â  const [deleteMergeJob] = await bigQueryClient.createQueryJob(deleteMergeOptions);
Â  Â  Â  Â  Â  Â  await deleteMergeJob.getQueryResults(); // Wait for delete to complete
Â  Â  Â  Â  Â  Â  console.log(`Backend: Existing Per_Key_Per_Day entries for Key ${targetKey} deleted using MERGE.`);


Â  Â  Â  Â  Â  Â  // 2b. Insert new Per_Key_Per_Day entries (Same as previous step 3)
Â  Â  Â  Â  Â  Â  const insertRows = perKeyPerDayRows.map(row => ({
Â  Â  Â  Â  Â  Â  Â  Â  Key: targetKey, // Use the fixed integer key
Â  Â  Â  Â  Â  Â  Â  Â  Day: row.Day,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Duration: parseInt(row.Duration, 10),Â 
Â  Â  Â  Â  Â  Â  Â  Â  Duration_Unit: row.Duration_Unit,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Planned_Delivery_Slot: row.Planned_Delivery_Slot || null,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Responsibility: row.Responsibility,Â 
Â  Â  Â  Â  Â  Â  }));
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  const perKeyPerDaySchema = [
Â  Â  Â  Â  Â  Â  Â  Â  { name: 'Key', type: 'INTEGER' },
Â  Â  Â  Â  Â  Â  Â  Â  { name: 'Day', type: 'DATE' },
Â  Â  Â  Â  Â  Â  Â  Â  { name: 'Duration', type: 'INTEGER' },
Â  Â  Â  Â  Â  Â  Â  Â  { name: 'Duration_Unit', type: 'STRING' },
Â  Â  Â  Â  Â  Â  Â  Â  { name: 'Planned_Delivery_Slot', type: 'STRING', mode: 'NULLABLE' },
Â  Â  Â  Â  Â  Â  Â  Â  { name: 'Responsibility', type: 'STRING' },
Â  Â  Â  Â  Â  Â  ];

Â  Â  Â  Â  Â  Â  await bigQueryClient
Â  Â  Â  Â  Â  Â  Â  Â  .dataset(bigQueryDataset)
Â  Â  Â  Â  Â  Â  Â  Â  .table(bigQueryTable2)
Â  Â  Â  Â  Â  Â  Â  Â  .insert(insertRows, { schema: perKeyPerDaySchema });
Â  Â  Â  Â  Â  Â  console.log(`Backend: New Per_Key_Per_Day entries for Key ${targetKey} inserted successfully.`);
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  console.log('Backend: No perKeyPerDayRows to insert.');
Â  Â  Â  Â  }


Â  Â  Â  Â  res.status(200).send({ message: 'Task and associated schedule data updated successfully.' });

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('Backend: Error updating task and schedule in BigQuery:', error);
Â  Â  Â  Â  if (error.response && error.response.insertErrors) {
Â  Â  Â  Â  Â  Â  console.error('Backend: BigQuery specific insert errors details:');
Â  Â  Â  Â  Â  Â  error.response.insertErrors.forEach((insertError, index) => {
Â  Â  Â  Â  Â  Â  Â  Â  console.error(`Backend: Row ${index} had errors:`);
Â  Â  Â  Â  Â  Â  Â  Â  insertError.errors.forEach(e => console.error(`Backend: - Reason: ${e.reason}, Message: ${e.message}`));
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Backend: Raw row that failed:', JSON.stringify(insertError.row, null, 2));
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  } else if (error.code && error.errors) {
Â  Â  Â  Â  Â  Â  console.error('Backend: Google Cloud API Error:', JSON.stringify(error.errors, null, 2));
Â  Â  Â  Â  }

Â  Â  Â  Â  res.status(500).json({
Â  Â  Â  Â  Â  Â  message: 'Failed to update task due to a backend error.',
Â  Â  Â  Â  Â  Â  details: error.message || 'Unknown server error.',
Â  Â  Â  Â  Â  Â  bigQueryErrorDetails: error.response?.insertErrors ? JSON.stringify(error.response.insertErrors) : null,
Â  Â  Â  Â  });
Â  Â  }
});

// Delete Task from BigQuery
app.delete('/api/data/:deliveryCode', async (req, res) => {
Â  Â  const { deliveryCode } = req.params;
Â  Â  console.log("Backend: Delete request for deliveryCode:", deliveryCode);
Â  Â  const query = `
Â  Â  Â  Â  DELETE FROM \`${projectId}.${bigQueryDataset}.${bigQueryTable}\`
Â  Â  Â  Â  WHERE DelCode_w_o__ = @deliveryCode
Â  Â  `;

Â  Â  const options = {
Â  Â  Â  Â  query: query,
Â  Â  Â  Â  params: { deliveryCode },
Â  Â  };

Â  Â  try {
Â  Â  Â  Â  const [job] = await bigQueryClient.createQueryJob(options);
Â  Â  Â  Â  await job.getQueryResults();
Â  Â  Â  Â  res.status(200).send({ message: 'All tasks with the specified delivery code were deleted successfully.' });
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('Backend: Error deleting tasks from BigQuery:', error);
Â  Â  Â  Â  res.status(500).send({ error: 'Failed to delete tasks from BigQuery.' });
Â  Â  }
});

const PORT = process.env.PORT || 3001;
app.listen(PORT, () => {
Â  Â  console.log(`Server running on port ${PORT}`);
});
